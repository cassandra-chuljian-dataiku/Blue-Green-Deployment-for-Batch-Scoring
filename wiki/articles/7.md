# Model Evaluation & Checks.

There are 3 implemented ways to perform evaluations through this project.

- Saved Model (SM) Metrics & Checks.
- Model Evaluation Store (MES) Metrics & Checks.
- Dataset Metrics & Checks (for anything that doesn't fit in SM or MES)

This article will explain how and when to use each type of evaluation.
For all the evaluation methods listed, we will be leveraging **DSS Checks**. 
These checks will be run in sceanrios and actions can be defined  based on the return status  :  _OK_ ,  _WARNING_  or  _ERROR_.

## 1)  Saved Model (SM) Metrics & Checks

 **What**  : SMs stores and versions trained models. Each trained model is evaluate at training on a hold out test dataset generating performance metrics (built-in or custom).

 **How**  : Checks can be defined for each of these metrics and will run at the end of each run of the model in the SMl Checks tab.
 
 **Usage** : SM Checks should be use when we want to monitor the metrics computed for the model at training time.
 
   _Example_ : In this project, we check the training F1 score for the classification model at training time.
 
 ## 2) Model Evaluation Store (MES) Metrics & Checks.
 
 **What** : MES are used to evaluate a trained model on an evaluation dataset. At each evaluation, the MES can compute data drift, prediction drift (no labelled dataset required) and Performance metrics & drift (if labels are provided)
 
 **How** : Checks on the computed metrics can be defined in the MES under the _Settings > Status Tab_. 
 
 **Usage** :  The MES Checks should be used when we need to evalate two models on the same evalation data OR if we are interested in computing data drift between the data a model was trained on and new data.

 _Example_ : In the project, the MES is used to: 
- Monitor data/performance drift when a model is fully deployed and
- Compare the model performance of the Challenger model with the Champion model **on the same evaluation dataset** before starting the deployment process.

 ## 3) Dataset Metrics & Checks.
 
 **What** : Dataset Metrics & Checks on datasets computes metric values on the dataset & allows the user to check them with checks.
 
 **How** Metrics and Checks can be defined in the Datasets  _Status tab_ .
 
 **Usage** : Metrics and checks on dataset should be use for any evaluations that are required to be computed in the flow outside of the SM & MES.
 
 Ex: In this project there we need to compute custom business metrics that need to be computed apart from the model itself.
 - R2 : Requires a conversion of the predicted classes to a price.
 - uptake & PPP : Require historical baggage booking data to be computed.
 
 






